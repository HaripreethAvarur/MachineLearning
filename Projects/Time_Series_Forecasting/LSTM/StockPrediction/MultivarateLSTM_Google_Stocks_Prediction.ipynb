{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n-----Imports-----\n<br>\n", "import numpy as np<br>\n", "from tensorflow.keras.models import Sequential<br>\n", "from tensorflow.keras.layers import LSTM<br>\n", "from tensorflow.keras.layers import Dense, Dropout<br>\n", "import pandas as pd<br>\n", "from matplotlib import pyplot as plt<br>\n", "from sklearn.preprocessing import StandardScaler<br>\n", "import seaborn as sns<br>\n", "#from datetime import datetime<br>\n", "#%%<br>\n", "----Reading CSV-----\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = pd.read_csv(\"D:\\\\myProjects\\\\Time Series Forecasting_LSTM\\\\Dataset\\\\GOOG.csv\")\n", "print(df.head()) "]}, {"cell_type": "markdown", "metadata": {}, "source": ["eparate dates for future plotting"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_dates = pd.to_datetime(df['Date'])\n", "print(train_dates.tail(15)) #Check last few dates. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["ariables for training"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cols = list(df)[1:6]\n", "#Date and volume columns are not used in training. \n", "print(cols) #['Open', 'High', 'Low', 'Close', 'Adj Close']"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ew dataframe with only training data - 5 columns"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_for_training = df[cols].astype(float)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["df_for_plot=df_for_training.tail(5000)<br>\n", "df_for_plot.plot.line()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["STM uses sigmoid and tanh that are sensitive to magnitude so values need to be normalized<br>\n", "normalize the dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["scaler = StandardScaler()\n", "scaler = scaler.fit(df_for_training)\n", "df_for_training_scaled = scaler.transform(df_for_training)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["s required for LSTM networks, we require to reshape an input data into n_samples x timesteps x n_features. <br>\n", "n this example, the n_features is 5. We will make timesteps = 14 (past days data used for training). "]}, {"cell_type": "markdown", "metadata": {}, "source": ["mpty lists to be populated using formatted training data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["trainX = []\n", "trainY = []"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["n_future = 1   # Number of days we want to look into the future based on the past days.\n", "n_past = 14  # Number of past days we want to use to predict the future."]}, {"cell_type": "markdown", "metadata": {}, "source": ["eformat input data into a shape: (n_samples x timesteps x n_features)<br>\n", "n my example, my df_for_training_scaled has a shape (12823, 5)<br>\n", "2823 refers to the number of data points and 5 refers to the columns (multi-variables)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in range(n_past, len(df_for_training_scaled) - n_future +1):\n", "    trainX.append(df_for_training_scaled[i - n_past:i, 0:df_for_training.shape[1]])\n", "    trainY.append(df_for_training_scaled[i + n_future - 1:i + n_future, 0])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["trainX, trainY = np.array(trainX), np.array(trainY)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('trainX shape == {}.'.format(trainX.shape))\n", "print('trainY shape == {}.'.format(trainY.shape))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["n my case, trainX has a shape (12809, 14, 5). <br>\n", "2809 because we are looking back 14 days (12823 - 14 = 12809). <br>\n", "emember that we cannot look back 14 days until we get to the 15th day. <br>\n", "lso, trainY has a shape (12809, 1). Our model only predicts a single value, but <br>\n", "t needs multiple variables (5 in my example) to make this prediction. <br>\n", "his is why we can only predict a single day after our training, the day after where our data ends.<br>\n", "o predict more days in future, we need all the 5 variables which we do not have. <br>\n", "e need to predict all variables if we want to do that. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["define the Autoencoder model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = Sequential()\n", "model.add(LSTM(64, activation='relu', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n", "model.add(LSTM(32, activation='relu', return_sequences=False))\n", "model.add(Dropout(0.2))\n", "model.add(Dense(trainY.shape[1]))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.compile(optimizer='adam', loss='mse')\n", "model.summary()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["fit the model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["history = model.fit(trainX, trainY, epochs=100, batch_size=16, validation_split=0.1, verbose=1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot(history.history['loss'], label='Training loss')\n", "plt.plot(history.history['val_loss'], label='Validation loss')\n", "plt.legend()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["redicting...<br>\n", "ibraries that will help us extract only business days in the US.<br>\n", "therwise our dates would be wrong when we look back (or forward).  "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pandas.tseries.holiday import USFederalHolidayCalendar\n", "from pandas.tseries.offsets import CustomBusinessDay\n", "us_bd = CustomBusinessDay(calendar=USFederalHolidayCalendar())\n", "#Remember that we can only predict one day in future as our model needs 5 variables\n", "#as inputs for prediction. We only have all 5 variables until the last day in our dataset.\n", "n_past = 16\n", "n_days_for_prediction=15  #let us predict past 15 days"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["predict_period_dates = pd.date_range(list(train_dates)[-n_past], periods=n_days_for_prediction, freq=us_bd).tolist()\n", "print(predict_period_dates)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ake prediction"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["prediction = model.predict(trainX[-n_days_for_prediction:]) #shape = (n, 1) where n is the n_days_for_prediction"]}, {"cell_type": "markdown", "metadata": {}, "source": ["erform inverse transformation to rescale back to original range<br>\n", "ince we used 5 variables for transform, the inverse expects same dimensions<br>\n", "herefore, let us copy our values 5 times and discard them after inverse transform"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["prediction_copies = np.repeat(prediction, df_for_training.shape[1], axis=-1)\n", "y_pred_future = scaler.inverse_transform(prediction_copies)[:,0]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Convert timestamp to date"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["forecast_dates = []\n", "for time_i in predict_period_dates:\n", "    forecast_dates.append(time_i.date())\n", "    \n", "df_forecast = pd.DataFrame({'Date':np.array(forecast_dates), 'Open':y_pred_future})\n", "df_forecast['Date']=pd.to_datetime(df_forecast['Date'])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["original = df[['Date', 'Open']]\n", "original['Date']=pd.to_datetime(original['Date'])\n", "original = original.loc[original['Date'] >= '2020-5-1']"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.lineplot(original['Date'], original['Open'])\n", "sns.lineplot(df_forecast['Date'], df_forecast['Open'])"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}